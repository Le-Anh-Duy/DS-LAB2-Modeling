{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68d5b7f",
   "metadata": {},
   "source": [
    "## 1. Setup & Import\n",
    "\n",
    "ƒê·∫ßu ti√™n, c·∫ßn thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import module `src` t·ª´ th∆∞ m·ª•c `23127011`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5871d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project Root: d:\\Coding\\School\\Y3-K1\\Intro2DS\\DS - LAB 2\\Milestone2_Project\\23127011\n",
      "üìÇ Src Parent:   d:\\Coding\\School\\Y3-K1\\Intro2DS\\DS - LAB 2\\Milestone2_Project\\23127011\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n project\n",
    "# Notebook n·∫±m trong: Milestone2_Project/23127011/notebooks/\n",
    "# Src n·∫±m trong: Milestone2_Project/23127011/src/\n",
    "\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.dirname(NOTEBOOK_DIR)  # 23127011\n",
    "SRC_PARENT = PROJECT_ROOT  # Th∆∞ m·ª•c ch·ª©a src\n",
    "\n",
    "# Th√™m v√†o sys.path ƒë·ªÉ import ƒë∆∞·ª£c\n",
    "if SRC_PARENT not in sys.path:\n",
    "    sys.path.insert(0, SRC_PARENT)\n",
    "\n",
    "print(f\"üìÇ Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"üìÇ Src Parent:   {SRC_PARENT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35070700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Import th√†nh c√¥ng!\n"
     ]
    }
   ],
   "source": [
    "# Import c√°c module c·∫ßn thi·∫øt\n",
    "from src import (\n",
    "    run_full_pipeline,          # Ch·∫°y to√†n b·ªô pipeline\n",
    "    run_processing_pipeline,    # Ch·ªâ Phase 1\n",
    "    run_matching_pipeline,      # Ch·ªâ Phase 2\n",
    ")\n",
    "from src.config import PipelineConfig, create_config\n",
    "\n",
    "print(\"‚úÖ Import th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b2123",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. C·∫•u h√¨nh Pipeline\n",
    "\n",
    "Thi·∫øt l·∫≠p c√°c ƒë∆∞·ªùng d·∫´n input/output v√† c√°c tham s·ªë c·∫•u h√¨nh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ef814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Data Raw:   d:\\Coding\\School\\Y3-K1\\Intro2DS\\DS - LAB 2\\Milestone2_Project\\23127011\\../data_raw_test\n",
      "üìÇ Data Output: d:\\Coding\\School\\Y3-K1\\Intro2DS\\DS - LAB 2\\Milestone2_Project\\23127011\\data_output_tutorial\n",
      "‚öôÔ∏è  Parallel:    True\n",
      "‚öôÔ∏è  Workers:     20\n"
     ]
    }
   ],
   "source": [
    "# === C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ===\n",
    "\n",
    "# Input: Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu LaTeX th√¥\n",
    "# C√≥ th·ªÉ d√πng 'data_raw_test' ƒë·ªÉ test v·ªõi dataset nh·ªè\n",
    "DATA_RAW = os.path.join(PROJECT_ROOT, '../', 'data_raw_test')\n",
    "\n",
    "# Output: Th∆∞ m·ª•c xu·∫•t k·∫øt qu·∫£\n",
    "DATA_OUTPUT = os.path.join(PROJECT_ROOT, 'data_output_tutorial')\n",
    "\n",
    "# === C·∫§U H√åNH X·ª¨ L√ù ===\n",
    "\n",
    "# S·ª≠ d·ª•ng x·ª≠ l√Ω song song ƒë·ªÉ tƒÉng t·ªëc\n",
    "USE_PARALLEL = True\n",
    "\n",
    "# S·ªë lu·ªìng (None = auto-detect t·ª´ s·ªë CPU)\n",
    "MAX_WORKERS = os.cpu_count() or 4\n",
    "\n",
    "print(f\"üìÇ Data Raw:   {DATA_RAW}\")\n",
    "print(f\"üìÇ Data Output: {DATA_OUTPUT}\")\n",
    "print(f\"‚öôÔ∏è  Parallel:    {USE_PARALLEL}\")\n",
    "print(f\"‚öôÔ∏è  Workers:     {MAX_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c4b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T√¨m th·∫•y 11 papers trong data_raw\n",
      "   V√≠ d·ª•: ['2403-00530', '2403-00531', '2403-00532', '2403-00533', '2403-00534']\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra data_raw t·ªìn t·∫°i v√† c√≥ bao nhi√™u papers\n",
    "if os.path.exists(DATA_RAW):\n",
    "    papers = [f for f in os.listdir(DATA_RAW) \n",
    "              if os.path.isdir(os.path.join(DATA_RAW, f))]\n",
    "    print(f\"‚úÖ T√¨m th·∫•y {len(papers)} papers trong data_raw\")\n",
    "    if papers:\n",
    "        print(f\"   V√≠ d·ª•: {papers[:5]}\")\n",
    "else:\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {DATA_RAW}\")\n",
    "    print(\"   H√£y ƒë·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n DATA_RAW ch√≠nh x√°c!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1eabd",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Phase 1: Pre-processing & Parsing\n",
    "\n",
    "Phase n√†y th·ª±c hi·ªán:\n",
    "1. **Flatten LaTeX**: G·ªôp `\\input`, `\\include` th√†nh 1 file\n",
    "2. **Extract References**: Tr√≠ch xu·∫•t t·ª´ `.bbl`, `.bib`, `\\bibitem`\n",
    "3. **Dedup References**: Lo·∫°i b·ªè reference tr√πng l·∫∑p\n",
    "4. **Build Structure Tree**: X√¢y d·ª±ng c√¢y Section/Subsection\n",
    "5. **Process Content**: L√†m s·∫°ch v√† t√°ch c√¢u\n",
    "6. **Export**: `hierarchy.json`, `refs.bib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861dd870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu Phase 1: Pre-processing & Parsing...\n",
      "   Log file: d:\\Coding\\School\\Y3-K1\\Intro2DS\\DS - LAB 2\\Milestone2_Project\\23127011\\data_output_tutorial\\pipeline.log\n",
      "\n",
      "\n",
      "‚úÖ Phase 1 ho√†n th√†nh!\n"
     ]
    }
   ],
   "source": [
    "# Ch·∫°y Phase 1\n",
    "print(\"üöÄ B·∫Øt ƒë·∫ßu Phase 1: Pre-processing & Parsing...\")\n",
    "print(f\"   Log file: {os.path.join(DATA_OUTPUT, 'pipeline.log')}\")\n",
    "print()\n",
    "\n",
    "run_processing_pipeline(\n",
    "    data_raw_path=DATA_RAW,\n",
    "    data_output_path=DATA_OUTPUT,\n",
    "    parallel=USE_PARALLEL,\n",
    "    max_workers=MAX_WORKERS\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Phase 1 ho√†n th√†nh!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47de9a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ƒê√£ x·ª≠ l√Ω: 11 papers\n",
      "\n",
      "üìÅ N·ªôi dung c·ªßa '2403-00530':\n",
      "   - hierarchy.json (166,426 bytes)\n",
      "   - metadata.json (462 bytes)\n",
      "   - references.json (31,668 bytes)\n",
      "   - refs.bib (97,894 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra k·∫øt qu·∫£ Phase 1\n",
    "if os.path.exists(DATA_OUTPUT):\n",
    "    output_folders = os.listdir(DATA_OUTPUT)\n",
    "    # L·ªçc b·ªè file log\n",
    "    output_folders = [f for f in output_folders \n",
    "                      if os.path.isdir(os.path.join(DATA_OUTPUT, f))]\n",
    "    \n",
    "    print(f\"üìä ƒê√£ x·ª≠ l√Ω: {len(output_folders)} papers\")\n",
    "    \n",
    "    if output_folders:\n",
    "        # Xem n·ªôi dung 1 paper m·∫´u\n",
    "        sample = output_folders[0]\n",
    "        sample_path = os.path.join(DATA_OUTPUT, sample)\n",
    "        print(f\"\\nüìÅ N·ªôi dung c·ªßa '{sample}':\")\n",
    "        for f in os.listdir(sample_path):\n",
    "            fpath = os.path.join(sample_path, f)\n",
    "            size = os.path.getsize(fpath)\n",
    "            print(f\"   - {f} ({size:,} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863e0b1",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Phase 2: Reference Matching\n",
    "\n",
    "Phase n√†y th·ª±c hi·ªán:\n",
    "1. **Load Ground Truth**: ƒê·ªçc `references.json` (t·ª´ arXiv API)\n",
    "2. **Load Extracted Refs**: ƒê·ªçc `refs.bib` t·ª´ Phase 1\n",
    "3. **TF-IDF Matching**: So kh·ªõp b·∫±ng cosine similarity\n",
    "4. **Export**: `labels.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677fd309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç B·∫Øt ƒë·∫ßu Phase 2: Reference Matching...\n",
      "\n",
      "üöÄ Starting Matching Pipeline (Phase 2.2)...\n",
      "   Target: d:\\Coding\\School\\Y3-K1\\Intro2DS\\DS - LAB 2\\Milestone2_Project\\23127011\\data_output_tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching References: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:01<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matching Complete. 'labels.json' generated in all folders.\n",
      "\n",
      "‚úÖ Phase 2 ho√†n th√†nh!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ch·∫°y Phase 2\n",
    "print(\"üîç B·∫Øt ƒë·∫ßu Phase 2: Reference Matching...\")\n",
    "print()\n",
    "\n",
    "run_matching_pipeline(DATA_OUTPUT)\n",
    "\n",
    "print(\"\\n‚úÖ Phase 2 ho√†n th√†nh!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804cca8",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Ki·ªÉm tra k·∫øt qu·∫£\n",
    "\n",
    "Xem chi ti·∫øt c√°c file output ƒë∆∞·ª£c t·∫°o ra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af9d1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Chi ti·∫øt paper: 2403-00530\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Ch·ªçn m·ªôt paper ƒë·ªÉ xem chi ti·∫øt\n",
    "if os.path.exists(DATA_OUTPUT):\n",
    "    folders = [f for f in os.listdir(DATA_OUTPUT) \n",
    "               if os.path.isdir(os.path.join(DATA_OUTPUT, f))]\n",
    "    \n",
    "    if folders:\n",
    "        sample_paper = folders[0]\n",
    "        sample_path = os.path.join(DATA_OUTPUT, sample_paper)\n",
    "        \n",
    "        print(f\"üìÑ Chi ti·∫øt paper: {sample_paper}\")\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9829df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä hierarchy.json:\n",
      "   - Versions: ['1', '2']\n",
      "   - Elements: 360 unique items\n",
      "\n",
      "   Sample elements:\n",
      "   [2403-00530-2403-00530v1-document-b11dd971-36d1-42cf-a133-b0d34b600614]: Root Document\n",
      "   [2403-00530-2403-00530v1-title-ffcee407-17c2-4405-bc53-10d2b007d6a1]: Extended Hubbard corrected tight-binding model for rhombohedral few-layer graphene\n",
      "   [2403-00530-2403-00530v1-authors-bd9f9e87-8d89-49d8-a40f-16aafb875681]: Dongkyu Lee, Wooil Yang, Young-Woo Son, Jeil Jung\n"
     ]
    }
   ],
   "source": [
    "# Xem hierarchy.json (c·∫•u tr√∫c document)\n",
    "hierarchy_path = os.path.join(sample_path, 'hierarchy.json')\n",
    "\n",
    "if os.path.exists(hierarchy_path):\n",
    "    with open(hierarchy_path, 'r', encoding='utf-8') as f:\n",
    "        hierarchy = json.load(f)\n",
    "    \n",
    "    print(\"üìä hierarchy.json:\")\n",
    "    print(f\"   - Versions: {list(hierarchy.get('hierarchy', {}).keys())}\")\n",
    "    print(f\"   - Elements: {len(hierarchy.get('elements', {}))} unique items\")\n",
    "    \n",
    "    # Xem v√†i element m·∫´u\n",
    "    elements = hierarchy.get('elements', {})\n",
    "    sample_keys = list(elements.keys())[:3]\n",
    "    print(\"\\n   Sample elements:\")\n",
    "    for k in sample_keys:\n",
    "        content = elements[k][:100] + \"...\" if len(elements[k]) > 100 else elements[k]\n",
    "        print(f\"   [{k}]: {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b33b5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö refs.bib: 66 unique references\n",
      "\n",
      "   Sample entry:\n",
      "   @misc{ref_0,\n",
      "  text = {@article{Anisimov1991PRB,\n",
      "  pages = {943--954},\n",
      "  year = {1991},\n",
      "  month = {July},\n",
      "  author = {Anisimov, Vladimir I. and Zaanen, Jan and Andersen, Ole K.},\n",
      "  journal = {Physical Review B},\n",
      "  urldate = {2024-01-29},\n",
      "  number = {3},\n",
      "  abstract = {We propose a form for the exchange-co...\n"
     ]
    }
   ],
   "source": [
    "# Xem refs.bib (references ƒë√£ dedup)\n",
    "refs_path = os.path.join(sample_path, 'refs.bib')\n",
    "\n",
    "if os.path.exists(refs_path):\n",
    "    with open(refs_path, 'r', encoding='utf-8') as f:\n",
    "        refs_content = f.read()\n",
    "    \n",
    "    # ƒê·∫øm s·ªë refs\n",
    "    num_refs = refs_content.count('@misc')\n",
    "    print(f\"üìö refs.bib: {num_refs} unique references\")\n",
    "    \n",
    "    # Xem 1 entry m·∫´u\n",
    "    print(\"\\n   Sample entry:\")\n",
    "    first_entry = refs_content.split('@misc')[1] if num_refs > 0 else \"\"\n",
    "    print(f\"   @misc{first_entry[:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c1c61a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è  labels.json: 33 matched references\n",
      "\n",
      "   Sample match:\n",
      "   Key: ref_2\n",
      "   Content: @article{Kulik2006PRL,\n",
      "pages = {103001},\n",
      "year = {2006},\n",
      "month = {September},\n",
      "author = {Kulik, Heathe...\n",
      "   -> Matched to: Density functional theory in transition-metal chemistry: a s...\n",
      "   -> Score: 0.823\n"
     ]
    }
   ],
   "source": [
    "# Xem labels.json (k·∫øt qu·∫£ matching)\n",
    "labels_path = os.path.join(sample_path, 'labels.json')\n",
    "\n",
    "if os.path.exists(labels_path):\n",
    "    with open(labels_path, 'r', encoding='utf-8') as f:\n",
    "        labels = json.load(f)\n",
    "    \n",
    "    print(f\"üè∑Ô∏è  labels.json: {len(labels)} matched references\")\n",
    "    \n",
    "    if labels:\n",
    "        # Xem 1 label m·∫´u\n",
    "        sample_label = labels[0]\n",
    "        print(\"\\n   Sample match:\")\n",
    "        print(f\"   Key: {sample_label.get('key')}\")\n",
    "        print(f\"   Content: {sample_label.get('content', '')[:100]}...\")\n",
    "        \n",
    "        gt = sample_label.get('ground_truth', {})\n",
    "        print(f\"   -> Matched to: {gt.get('title', 'N/A')[:60]}...\")\n",
    "        print(f\"   -> Score: {gt.get('match_score', 'N/A')}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  labels.json ch∆∞a ƒë∆∞·ª£c t·∫°o (c√≥ th·ªÉ do thi·∫øu references.json)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504e286",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Ch·∫°y Full Pipeline (One-liner)\n",
    "\n",
    "N·∫øu mu·ªën ch·∫°y c·∫£ 2 phases c√πng l√∫c, s·ª≠ d·ª•ng `run_full_pipeline()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f28aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Output: d:\\Coding\\School\\Y3-K1\\Intro2DS\\DS - LAB 2\\Milestone2_Project\\23127011\\data_output_full_demo\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªãnh nghƒ©a output m·ªõi ƒë·ªÉ kh√¥ng ghi ƒë√® k·∫øt qu·∫£ tr∆∞·ªõc\n",
    "DATA_OUTPUT_FULL = os.path.join(PROJECT_ROOT, 'data_output_full_demo')\n",
    "\n",
    "print(f\"üìÇ Output: {DATA_OUTPUT_FULL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adad5bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ PHASE 1: Pre-processing & Parsing\n",
      "============================================================\n",
      "\n",
      "‚úÖ Phase 1 Complete: 11 papers processed\n",
      "\n",
      "============================================================\n",
      "üîç PHASE 2: Reference Matching\n",
      "============================================================\n",
      "üöÄ Starting Matching Pipeline (Phase 2.2)...\n",
      "   Target: d:\\Coding\\School\\Y3-K1\\Intro2DS\\DS - LAB 2\\Milestone2_Project\\23127011\\data_output_full_demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching References: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:01<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matching Complete. 'labels.json' generated in all folders.\n",
      "\n",
      "‚úÖ Phase 2 Complete: 8 papers matched\n",
      "\n",
      "============================================================\n",
      "üéâ PIPELINE COMPLETE!\n",
      "   Output: d:\\Coding\\School\\Y3-K1\\Intro2DS\\DS - LAB 2\\Milestone2_Project\\23127011\\data_output_full_demo\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "üìä K·∫æT QU·∫¢ T·ªîNG H·ª¢P:\n",
      "   Papers processed: 11\n",
      "   Papers matched:   8\n",
      "   Output path:      d:\\Coding\\School\\Y3-K1\\Intro2DS\\DS - LAB 2\\Milestone2_Project\\23127011\\data_output_full_demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ch·∫°y full pipeline v·ªõi 1 l·ªánh duy nh·∫•t\n",
    "result = run_full_pipeline(\n",
    "    data_raw=DATA_RAW,\n",
    "    data_output=DATA_OUTPUT_FULL,\n",
    "    parallel=True,\n",
    "    max_workers=MAX_WORKERS,\n",
    "    run_matching=True,  # C√≥ ch·∫°y matching kh√¥ng\n",
    "    verbose=True        # In th√¥ng tin ti·∫øn tr√¨nh\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä K·∫æT QU·∫¢ T·ªîNG H·ª¢P:\")\n",
    "print(f\"   Papers processed: {result['processed']}\")\n",
    "print(f\"   Papers matched:   {result['matched']}\")\n",
    "print(f\"   Output path:      {result['output_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fac5f5",
   "metadata": {},
   "source": [
    "## üìù Ghi ch√∫ th√™m\n",
    "\n",
    "### Ch·∫°y t·ª´ Command Line\n",
    "```bash\n",
    "# T·ª´ th∆∞ m·ª•c 23127011/\n",
    "cd Milestone2_Project/23127011\n",
    "\n",
    "# Full pipeline\n",
    "python -m src.main --raw ../data_raw --output ../data_output --parallel\n",
    "\n",
    "# Ch·ªâ processing\n",
    "python -m src.main --raw ../data_raw --output ../data_output --no-matching\n",
    "\n",
    "# Ch·ªâ matching\n",
    "\n",
    "python -m src.main --output ../data_output --matching-only\n",
    "```\n",
    "\n",
    "### X·ª≠ l√Ω l·ªói th∆∞·ªùng g·∫∑p\n",
    "\n",
    "1. **ModuleNotFoundError**: ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n `SRC_PARENT` ƒë√∫ng v√† ƒë√£ th√™m v√†o `sys.path`\n",
    "2. **FileNotFoundError**: Ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n `DATA_RAW`\n",
    "3. **Empty output**: Ki·ªÉm tra file log trong `DATA_OUTPUT/pipeline.log`\n",
    "\n",
    "### C·∫•u tr√∫c data_raw\n",
    "\n",
    "```bash\n",
    "data_raw/\n",
    "‚îú‚îÄ‚îÄ 2403-00530/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ tex/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ v1/\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tex\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ refs.bib\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ v2/\n",
    "‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ main.tex\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ metadata.json\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ references.json\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
