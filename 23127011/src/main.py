#!/usr/bin/env python
"""
LaTeX Paper Processing Pipeline - CLI Entry Point
==================================================

Ch·∫°y pipeline t·ª´ command line:

    # Ch·∫°y full pipeline (x·ª≠ l√Ω + matching)
    python -m src.main --raw ./data_raw --output ./data_output

    # Ch·ªâ ch·∫°y phase 1 (x·ª≠ l√Ω)
    python -m src.main --raw ./data_raw --output ./data_output --no-matching

    # Ch·∫°y song song v·ªõi 8 threads
    python -m src.main --raw ./data_raw --output ./data_output --parallel --workers 8

    # Ch·ªâ ch·∫°y matching (ƒë√£ c√≥ data processed)
    python -m src.main --output ./data_output --matching-only

    # Merge labels th√†nh dataset
    python -m src.main --merge --yymm 2403 --limit 50
"""

import argparse
import os
import sys

def get_project_paths():
    """L·∫•y ƒë∆∞·ªùng d·∫´n project root t·ª´ v·ªã tr√≠ file hi·ªán t·∫°i."""
    current_file = os.path.abspath(__file__)
    src_dir = os.path.dirname(current_file)
    student_dir = os.path.dirname(src_dir)
    project_root = os.path.dirname(student_dir)
    return {
        "src": src_dir,
        "student": student_dir,
        "project": project_root,
        "data_raw_default": os.path.join(project_root, "data_raw"),
        "data_output_default": os.path.join(project_root, "data_output"),
        "dataset_final": os.path.join(project_root, "dataset_final")
    }


def cmd_process(args):
    """Ch·∫°y Phase 1: Pre-processing & Parsing."""
    from .pipeline import run_processing_pipeline
    
    print(f"üìÇ Input:  {args.raw}")
    print(f"üìÇ Output: {args.output}")
    print(f"‚öôÔ∏è  Parallel: {args.parallel} | Workers: {args.workers or 'auto'}")
    print()
    
    run_processing_pipeline(
        data_raw_path=args.raw,
        data_output_path=args.output,
        parallel=args.parallel,
        max_workers=args.workers
    )
    print("‚úÖ Phase 1 Complete!")


def cmd_matching(args):
    """Ch·∫°y Phase 2: Reference Matching."""
    from .run_matching import run_matching_pipeline
    
    print(f"üìÇ Data Output: {args.output}")
    print()
    
    run_matching_pipeline(args.output)
    print("‚úÖ Phase 2 Complete!")


def cmd_full(args):
    """Ch·∫°y Full Pipeline (Phase 1 + Phase 2)."""
    from . import run_full_pipeline
    
    result = run_full_pipeline(
        data_raw=args.raw,
        data_output=args.output,
        parallel=args.parallel,
        max_workers=args.workers,
        run_matching=not args.no_matching,
        verbose=True
    )
    
    print(f"\nüìä Summary:")
    print(f"   Processed: {result['processed']} papers")
    print(f"   Matched:   {result['matched']} papers")


def cmd_merge(args):
    """Ch·∫°y Phase 3: Merge Labels."""
    from .merge_labels import INPUT_DIR_PATH, OUTPUT_DIR
    import json
    import random
    
    # Override paths n·∫øu ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
    input_dir = args.input or INPUT_DIR_PATH
    output_dir = args.output_dataset or OUTPUT_DIR
    
    print(f"üìÇ Input:  {input_dir}")
    print(f"üìÇ Output: {output_dir}")
    print(f"üîë Prefix: {args.yymm}")
    
    if args.limit:
        print(f"üé≤ Mode: Random Limit ({args.limit})")
    elif args.range:
        print(f"‚úÇÔ∏è  Mode: Range [{args.range[0]} -> {args.range[1]}]")
    else:
        print("üöÄ Mode: Full Dataset")
    
    # Import v√† ch·∫°y logic merge
    # (Simplified version - full logic ƒë√£ c√≥ trong merge_labels.py)
    print("\n‚ö†Ô∏è  ƒê·ªÉ ch·∫°y merge v·ªõi ƒë·∫ßy ƒë·ªß options, s·ª≠ d·ª•ng:")
    print(f"   python -m src.merge_labels --yymm {args.yymm}", end="")
    if args.limit:
        print(f" --limit {args.limit}", end="")
    if args.range:
        print(f" --range {args.range[0]} {args.range[1]}", end="")
    print()


def main():
    parser = argparse.ArgumentParser(
        description="LaTeX Paper Processing Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Full pipeline
  python -m src.main --raw ./data_raw --output ./data_output
  
  # Processing only (no matching)
  python -m src.main --raw ./data_raw --output ./data_output --no-matching
  
  # Matching only (data already processed)
  python -m src.main --output ./data_output --matching-only
  
  # Merge labels into dataset
  python -m src.main --merge --yymm 2403 --limit 50
        """
    )
    
    paths = get_project_paths()
    
    # === Mode Selection ===
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument(
        "--matching-only", 
        action="store_true",
        help="Ch·ªâ ch·∫°y phase matching (b·ªè qua processing)"
    )
    mode_group.add_argument(
        "--merge",
        action="store_true", 
        help="Ch·∫°y merge labels th√†nh dataset"
    )
    
    # === Path Arguments ===
    parser.add_argument(
        "--raw", "-r",
        type=str,
        default=paths["data_raw_default"],
        help=f"ƒê∆∞·ªùng d·∫´n data raw (default: {paths['data_raw_default']})"
    )
    parser.add_argument(
        "--output", "-o",
        type=str,
        default=paths["data_output_default"],
        help=f"ƒê∆∞·ªùng d·∫´n output (default: {paths['data_output_default']})"
    )
    
    # === Processing Options ===
    parser.add_argument(
        "--parallel", "-p",
        action="store_true",
        help="S·ª≠ d·ª•ng x·ª≠ l√Ω song song"
    )
    parser.add_argument(
        "--workers", "-w",
        type=int,
        default=None,
        help="S·ªë workers cho parallel processing (default: s·ªë CPU)"
    )
    parser.add_argument(
        "--no-matching",
        action="store_true",
        help="Kh√¥ng ch·∫°y phase matching sau processing"
    )
    
    # === Merge Options ===
    parser.add_argument(
        "--yymm",
        type=str,
        help="Prefix nƒÉm-th√°ng cho merge (VD: 2403)"
    )
    parser.add_argument(
        "--limit",
        type=int,
        help="Gi·ªõi h·∫°n s·ªë papers random (cho merge)"
    )
    parser.add_argument(
        "--range",
        type=int,
        nargs=2,
        help="L·∫•y papers t·ª´ index A ƒë·∫øn B (cho merge)"
    )
    parser.add_argument(
        "--input",
        type=str,
        help="Override input path cho merge"
    )
    parser.add_argument(
        "--output-dataset",
        type=str,
        help="Override output path cho dataset merge"
    )
    
    args = parser.parse_args()
    
    # === Dispatch ===
    try:
        if args.merge:
            if not args.yymm:
                parser.error("--merge requires --yymm argument")
            cmd_merge(args)
        elif args.matching_only:
            cmd_matching(args)
        else:
            cmd_full(args)
            
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
